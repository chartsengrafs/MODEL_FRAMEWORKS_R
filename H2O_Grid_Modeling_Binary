
#Split the data 
splits <- h2o.splitFrame(hex, c(0.7,0.2),  seed=1234)  
train <- h2o.assign(splits[[1]], "train.hex")  
valid <- h2o.assign(splits[[2]], "valid.hex")   
test <- h2o.assign(splits[[3]], "test.hex")     
 
#################
# GBM GRID SEARCH
#################
 
#hyperparamters
gbm_params1 <- list(learn_rate = c(0.01, 0.1),max_depth = c(3, 5, 9),sample_rate = c(0.8, 1.0),
               col_sample_rate = c(0.2, 0.5, 1.0))

 #gRID

gbm_grid1 <- h2o.grid("gbm", x = c(2:23, 26, 28:52), y = 24,grid_id = "gbm_grid1",
training_frame = train,validation_frame = valid,ntrees = 100,seed = 1,hyper_params = gbm_params1)

 #GBM Grid Performance

gbm_gridperf <- h2o.getGrid(grid_id = "gbm_grid1",sort_by = "auc",decreasing = TRUE)

print(gbm_gridperf)

#Score test  set for final eval
best_gbm_perf <- h2o.performance(model = best_gbm, newdata = test)


# Grab the model_id for the top GBM model, chosen by validation AUC
best_gbm_model_id <- gbm_gridperf@model_ids[[1]]
best_gbm <- h2o.getModel(best_gbm_model_id)

 
#################
# GLM GRID SEARCH
#################
#hyper parameters - regularization 
glm_hyper_parameters = list(alpha=c(0.01,0.1,0.3,0.5,0.7,0.9),
lambda= c(1e-4,1e-5,1e-6,1e-7,1e-8) )

glm_grid1 <- h2o.grid("glm", x = c(2:23, 26, 28:52), y = 24, family='binomial',
grid_id = "glm_grid1",  training_frame = train,validation_frame = valid, hyper_params = glm_hyper_parameters)

 
#GLM Grid Performance

glm_gridperf <- h2o.getGrid(grid_id = "glm_grid1",sort_by = "auc",decreasing = TRUE)

#Evaluate on test set

best_glm_perf <- h2o.performance(model = best_glm, newdata = test)

h2o.auc(best_glm_perf)

# Grab the model_id for the top GBM model, chosen by validation AUC
best_glm_model_id <- glm_gridperf@model_ids[[1]]
best_glm <- h2o.getModel(best_glm_model_id)

 

###########################
# DEEP LEARNING GRID SEARCH
##########################

 
# Deeplearning hyperparamters

#Activation function
activation_opt <- c("Rectifier", "RectifierWithDropout", "TanHWithDropout")
#Regularization parameters
l1_opt <- c(0, 0.00001, 0.0001, 0.001, 0.01, 0.1)
l2_opt <- c(0, 0.00001, 0.0001, 0.001, 0.01, 0.1)

hyper_params <- list(activation = activation_opt,l1 = l1_opt,l2 = l2_opt)

search_criteria <- list(strategy = "RandomDiscrete",max_runtime_secs = 1200)

 

 #Grid

dl_grid <- h2o.grid("deeplearning", x = c(2:23, 26, 28:52), y = 24,grid_id = "dl_grid",
training_frame = train,validation_frame = valid,seed = 1,hidden = c(200,200),
hyper_params = hyper_params, search_criteria = search_criteria)

 
#DL grid performance
dl_gridperf <- h2o.getGrid(grid_id = "dl_grid",sort_by = "auc", decreasing = TRUE)

print(dl_gridperf)

 # Grab the model_id for the top DL model, chosen by validation AUC
best_dl_model_id <- dl_gridperf@model_ids[[1]]
best_dl <- h2o.getModel(best_dl_model_id)

#Evaluate test set with best dl model 
best_dl_perf <- h2o.performance(model = best_dl, newdata = test)

h2o.auc(best_dl_perf)  

 

 

############################
#RANDOM FORREST  GRID SEARCH
###########################

hyper_params <- list(ntrees=c(50,100,200),max_depth=c(5,10,15,20))

rf_grid <- h2o.grid("randomForest", x = c(2:23, 26, 28:52), y = 24,grid_id = "rf_grid",
training_frame = train, validation_frame = valid,hyper_params=hyper_params)

 

 #RFM performance

rf_gridperf <- h2o.getGrid(grid_id = "rf_grid",sort_by = "auc",decreasing = TRUE)


# Grab the model_id for the top RFM model, chosen by validation AUC
best_rf_model_id <-rf_gridperf@model_ids[[1]]
best_rf <- h2o.getModel(best_rf_model_id)

 

#Evaluate test set with best dl model 
best_rf_perf <- h2o.performance(model = best_rf, newdata = test)

h2o.auc(best_rf_perf)  

 

############################
#MANUAL LIFT CURVES ON TEST
###########################
 

 #to do - functionalize this code, add shiny interactivity

#Convert test hex to data frame from H2O
test_df<-as.data.frame(test)
#add index to test so we can merge the two datasets
test_df$ID <- seq.int(nrow(test_df))

 

#Score different 'best' models
score.test_rf=h2o.predict(object=best_rf, newdata=test)
score.test_gbm=h2o.predict(object=best_gbm, newdata=test)
score.test_glm=h2o.predict(object=best_glm, newdata=test)
score.test_dl=h2o.predict(object=best_dl, newdata=test)

 
#Convert scored scored hex's to dataframes
scored_df_rf<-as.data.frame(score.test_rf)
scored_df_gbm<-as.data.frame(score.test_gbm)
scored_df_glm<-as.data.frame(score.test_glm)
scored_df_dl<-as.data.frame(score.test_dl)

 
#add index so we can merge the scored data sets with data
scored_df_rf$ID <- seq.int(nrow(scored_df_rf))
scored_df_gbm$ID <- seq.int(nrow(scored_df_gbm))
scored_df_glm$ID <- seq.int(nrow(scored_df_glm))
scored_df_dl$ID <- seq.int(nrow(scored_df_dl))

 #merge them
full_test_score_rf=inner_join(scored_df_rf,test_df, by="ID" )
full_test_score_gbm=inner_join(scored_df_gbm,test_df, by="ID" )
full_test_score_glm=inner_join(scored_df_glm,test_df, by="ID" )
full_test_score_dl=inner_join(scored_df_dl,test_df, by="ID" )

 

#split score up into deciles
fts_rf <- full_test_score_rf %>% mutate(decile=ntile(p0,10))
fts_gbm <- full_test_score_gbm %>% mutate(decile=ntile(p0,10))
fts_glm <- full_test_score_glm %>% mutate(decile=ntile(p0,10))
fts_dl <- full_test_score_dl %>% mutate(decile=ntile(p0,10))

 
#Convert the response back to a 1/0 numeric variable

fts_rf$RESP <- as.numeric(fts_rf$RESP) - 1
fts_gbm$RESP <- as.numeric(fts_gbm$RESP) - 1
fts_glm$RESP <- as.numeric(fts_glm$RESP) - 1
fts_dl$RESP <- as.numeric(fts_dl$RESP) - 1

 

#Create cumulative response, base_line

rf <- fts_rf %>% select(decile,RESP) %>% group_by(decile) %>%
summarise(sresp_rf=sum(RESP)) %>% mutate(cum_resp_rf = cumsum(sresp_rf)) %>%
mutate(cum_pct_rf = cum_resp_rf/nrow(fts_rf[fts_rf$RESP==1,]))

gbm <- fts_gbm %>% select(decile,RESP) %>% group_by(decile) %>%summarise(sresp_gbm=sum(RESP)) %>%
mutate(cum_resp_gbm = cumsum(sresp_gbm)) %>%
mutate(cum_pct_gbm = cum_resp_gbm/nrow(fts_gbm[fts_gbm$RESP==1,]))

glm <- fts_glm %>% select(decile,RESP) %>% group_by(decile) %>%
summarise(sresp_glm=sum(RESP)) %>% mutate(cum_resp_glm = cumsum(sresp_glm)) %>%
mutate(cum_pct_glm = cum_resp_glm/nrow(fts_glm[fts_glm$RESP==1,]))

dl <- fts_dl %>% select(decile,RESP) %>% group_by(decile) %>%summarise(sresp_dl=sum(RESP)) %>%
mutate(cum_resp_dl = cumsum(sresp_dl)) %>%mutate(cum_pct_dl = cum_resp_dl/nrow(fts_glm[fts_dl$RESP==1,]))

 
#Merge the rankings
rank1=inner_join(rf,gbm, by="decile" )
rank2=inner_join(rank1,glm, by="decile")
rank3=inner_join(rank2,dl,by="decile")

#Create cumulative baseline
rank3$base_line = seq(0.1,1,by=0.1)

rank4<- rank3 %>%mutate(separation_rf=cum_pct_rf-base_line,separation_gbm=cum_pct_gbm-base_line ,

                        separation_glm=cum_pct_glm-base_line,  separation_dl=cum_pct_dl-base_line)

 
#####################################################
#FINAL EVALUATION OF BEST MODELS
####################################################

#Plot  lift curves

rank4 %>% ggplot(aes(x=decile)) + geom_line(aes(y=cum_pct_rf),color="red") +
geom_line(aes(y=base_line),color="black")+ geom_line(aes(y=cum_pct_gbm),color="blue") +
geom_line(aes(y=cum_pct_dl),color="orange") + geom_line(aes(y=cum_pct_glm),color="green")+
ggtitle("LIFT OVER RANDOM - TESTING SET") + theme_economist()

 #Examine max separation (Similar to KS)

 

summarize(rank4,max_RF_Separation=max(separation_rf),max_GBM_Separation=max(separation_gbm),
max_GLM_Separation=max(separation_glm),max_DL_Separation=max(separation_dl))  

  

#This is a good way to count rows with a where statement

nrow(fts[fts$RESP=='1',])

 

levels(fts$RESP)

 

#x=df[df#Y==1,] filters to y=1

 

 

#x=df[df#Y==1$&$f==b             

 

 

 

 

 

 

 
